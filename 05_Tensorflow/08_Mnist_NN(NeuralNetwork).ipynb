{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tkinter import *\n",
    "import tkinter.scrolledtext as tkst\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist   # 손글씨 인식 데이터 로딩식 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_fig = Figure(figsize=(4,4), dpi=100)\n",
    "digit_ax = digit_fig.add_subplot(111)\n",
    "digit_ax.set_title('Selected Digit Image')\n",
    "major_ticks = np.arange(0, 29, 5) # 주 눈금을 위한 배열 생성 (단위 5)\n",
    "minor_ticks = np.arange(0, 29, 1) # 보조 눈금 위한 배열 생성 (단위 1)\n",
    "digit_ax.set_xticks(major_ticks) # X 주눈금\n",
    "digit_ax.set_xticks(minor_ticks, minor=True) # X 보조눈금\n",
    "digit_ax.set_yticks(major_ticks) # Y 주눈금\n",
    "digit_ax.set_yticks(minor_ticks, minor=True) # Y 보조눈금\n",
    "digit_ax.grid(which='both') # 격자(grid) 생성 (which='both' : 주, 보조 눈금 모두)\n",
    "digit_ax.grid(which='minor', alpha=0.2) # 주눈금의 격자 투명도\n",
    "digit_ax.grid(which='major', alpha=0.5) # 보조 눈금의 격자 투명도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'History of loss')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss(코스트)의 변화 표시 차트 \n",
    "loss_fig = Figure(figsize=(4,4), dpi=100)\n",
    "loss_ax = loss_fig.add_subplot(111)\n",
    "loss_ax.set_xlabel('Epochs')\n",
    "loss_ax.set_ylabel('Loss')\n",
    "loss_ax.set_title('History of loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'History of accuracy')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도 변화 표시 차트\n",
    "acc_fig = Figure(figsize=(4,4), dpi=100)\n",
    "acc_ax = acc_fig.add_subplot(111)\n",
    "acc_ax.set_xlabel('Epochs')\n",
    "acc_ax.set_ylabel('Accuracy')\n",
    "acc_ax.set_title('History of accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Probalility Chart')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측한 숫자에 대한 정확도(10개의 확율값) 표시 차트\n",
    "number_fig = Figure(figsize=(4,4), dpi=100)\n",
    "number_ax = number_fig.add_subplot(111)\n",
    "number_ax.set_title('Probalility Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#print(x_train.shape)\n",
    "#print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewImage():\n",
    "    # 데이터를 로드,\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    # x_test 데이터의 원본을 x_test_original 변수에 복사\n",
    "    x_test_original = x_test\n",
    "    # 스핀 박스에 입력된 숫자를 추출 하고 -1 연산  : 배열은 0부터 시작하니까\n",
    "    t_a = int(t_aSpbox.get()) - 1\n",
    "    # x_test_original 배열의 selected_image 번째위치한 데이터를 그래프레 드로잉\n",
    "    # 데이터는 28*28 규격의 숫자  0~ 255 사이의 채도 가 저장되어 있음\n",
    "    selected_image = t_a\n",
    "    digit_ax.imshow( x_test_original[selected_image] )\n",
    "    digit_fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning():\n",
    "    import numpy as np\n",
    "    from keras import optimizers\n",
    "    from keras.layers import Dense\n",
    "    from keras.models import Sequential\n",
    "    # 데이터 로드\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_test_original = x_test\n",
    "    # 스핀 박스 데이터 추출\n",
    "    t_a = int(t_aSpbox.get()) - 1\n",
    "    t_t = int(t_tSpbox.get()) \n",
    "    selected_image = t_a\n",
    "    \n",
    "    # 모델 객체 생성\n",
    "    model = Sequential()\n",
    "    # relu 레이어 추가. 입력은 28*28 : (28,28) 데이터가 28*28 로 변경예정, 출력은 512\n",
    "    model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "    # softmax 레이어 추가. 출력 10개 -  \n",
    "    # 전체출력을 원핫 구조로 설정된 갯수만큼 변형해서 출력해는 레이어\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # 모델 설계\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', \\\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # 데이터 가공 : 원래 형태가 (60000, 28, 28)  이것을 입력 레이어 형태에 맞게 변형\n",
    "    x_train = x_train.reshape((60000, 28 * 28))\n",
    "    # 숫자가 0~255 사이이기 때문에 모두 1의 자리와 소수점아래 자리를 갖는 \n",
    "    # 데이터로 변형 - 학습 데이터와 테스트 데이터들의 표준화 과정\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.reshape((10000, 28 * 28))\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "    \n",
    "    from keras.utils import to_categorical\n",
    "    # 타겟값들을 케라스에서 제공하는 함수를 사용하여 원핫형태로 인코딩합니다\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    \n",
    "    # 학습된 모델저장 ModelCheckpoint,  \n",
    "    # 학습중 학습결과가 개선되지 않는 상태 지속시 조기 종료 를 위한 EarlyStopping\n",
    "    # 임포트\n",
    "    from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "    \n",
    "    # ModelCheckpoint와 EarlyStopping 의 객체를 생성\n",
    "    modelCheckpoint = ModelCheckpoint('best_digits_model.hdf5', save_best_only=True)\n",
    "    monitor_val_acc = EarlyStopping(monitor='val_accuracy', patience=10)\n",
    "    # 'best_digits_model.hdf5' : 저장될 모델의 이름\n",
    "    # monitor='val_accuracy' : 정확도를 이용한 모델학습 조기 종료 \n",
    "    # patience=5 : 5회 학습이상 정확도가 개선되지 않으면 종료\n",
    "    \n",
    "    # 학습\n",
    "    history = model.fit(x_train, y_train, validation_data=(x_test, y_test), \\\n",
    "        epochs=t_t, batch_size=128, callbacks=[monitor_val_acc, modelCheckpoint])\n",
    "    \n",
    "    # 예측\n",
    "    result = model.predict(np.array([x_test[selected_image]]))\n",
    "    # 가장 높은 확율의 인덱스를 얻어 내기 위해 argmax 함수 실행max 함수 실행\n",
    "    result_number = np.argmax(result)  \n",
    "    \n",
    "    # 그래프 드로잉\n",
    "    loss_ax.plot(history.history['loss'], 'ro', label='train loss')\n",
    "    loss_fig.canvas.draw()\n",
    "    \n",
    "    acc_ax.plot(history.history['accuracy'], 'bo', label='train acc')\n",
    "    acc_fig.canvas.draw()\n",
    "    \n",
    "    # 표시 라벨들표시 라벨들\n",
    "    digits = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "    x_pos = np.arange(len(digits))  # x 축 값들\n",
    "    # 차트에 표시될 10개의 확률들을 리스트로 저장\n",
    "    performance = [ val for val in result[0]]  \n",
    "    \n",
    "    # 10개의 확율중 가장큰 확율값의 인덱스를 갖고 있는  result_number 변수이용\n",
    "    # 가장 큰 확율(예측숫자의 확율)을 추출\n",
    "    result_probability = performance[result_number]\n",
    "    # 계산해 노은 x_pos(x 축데이터)와 performance(y축 데이터) 로 \n",
    "    # 차트를 그립니다\n",
    "    number_ax.bar(x_pos, performance, align='center', alpha=0.5)\n",
    "    \n",
    "    # 차트의 타이틀에 예측한 숫자와 그의 확율값을 표시합니다\n",
    "\n",
    "    number_ax.set_title('Number is %2i (probability %7.4f)' % (result_number, \\\n",
    "                                                        result_probability*100))\n",
    "    number_fig.canvas.draw()\n",
    "    # 각 열개의 확율들 출력\n",
    "    print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.4295 - accuracy: 0.8736 - val_loss: 0.1277 - val_accuracy: 0.9628\n",
      "Epoch 2/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1124 - accuracy: 0.9671 - val_loss: 0.0835 - val_accuracy: 0.9735\n",
      "Epoch 3/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0669 - accuracy: 0.9797 - val_loss: 0.0833 - val_accuracy: 0.9751\n",
      "Epoch 4/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0478 - accuracy: 0.9849 - val_loss: 0.0671 - val_accuracy: 0.9811\n",
      "Epoch 5/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0349 - accuracy: 0.9898 - val_loss: 0.0679 - val_accuracy: 0.9796\n",
      "Epoch 6/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0263 - accuracy: 0.9919 - val_loss: 0.0656 - val_accuracy: 0.9813\n",
      "Epoch 7/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0215 - accuracy: 0.9939 - val_loss: 0.0790 - val_accuracy: 0.9780\n",
      "Epoch 8/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.0731 - val_accuracy: 0.9796\n",
      "Epoch 9/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0735 - val_accuracy: 0.9808\n",
      "Epoch 10/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.0768 - val_accuracy: 0.9805\n",
      "Epoch 11/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0717 - val_accuracy: 0.9817\n",
      "Epoch 12/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0768 - val_accuracy: 0.9819\n",
      "Epoch 13/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0757 - val_accuracy: 0.9821\n",
      "Epoch 14/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0867 - val_accuracy: 0.9801\n",
      "Epoch 15/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0804 - val_accuracy: 0.9827\n",
      "Epoch 16/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0824 - val_accuracy: 0.9823\n",
      "Epoch 17/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0925 - val_accuracy: 0.9814\n",
      "Epoch 18/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0879 - val_accuracy: 0.9828\n",
      "Epoch 19/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0990 - val_accuracy: 0.9807\n",
      "Epoch 20/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 6.4625e-04 - accuracy: 0.9999 - val_loss: 0.0933 - val_accuracy: 0.9826\n",
      "Epoch 21/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 6.3870e-04 - accuracy: 0.9998 - val_loss: 0.0970 - val_accuracy: 0.9821\n",
      "Epoch 22/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 3.2508e-04 - accuracy: 0.9999 - val_loss: 0.1085 - val_accuracy: 0.9828\n",
      "Epoch 23/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 3.9857e-04 - accuracy: 0.9999 - val_loss: 0.1053 - val_accuracy: 0.9825\n",
      "Epoch 24/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 4.6429e-04 - accuracy: 0.9999 - val_loss: 0.1045 - val_accuracy: 0.9834\n",
      "Epoch 25/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 1.6425e-04 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9833\n",
      "Epoch 26/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 1.5575e-04 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9825\n",
      "Epoch 27/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 4.0744e-04 - accuracy: 0.9999 - val_loss: 0.1140 - val_accuracy: 0.9834\n",
      "Epoch 28/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 1.4325e-04 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9826\n",
      "Epoch 29/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 7.5581e-05 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9819\n",
      "Epoch 30/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 5.7455e-05 - accuracy: 1.0000 - val_loss: 0.1290 - val_accuracy: 0.9807\n",
      "Epoch 31/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 5.4963e-05 - accuracy: 1.0000 - val_loss: 0.1317 - val_accuracy: 0.9818\n",
      "Epoch 32/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 3.1887e-05 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.9831\n",
      "Epoch 33/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 2.3443e-05 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9826\n",
      "Epoch 34/100\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 1.9030e-05 - accuracy: 1.0000 - val_loss: 0.1297 - val_accuracy: 0.9826\n",
      "[3.0663936e-38, 1.8851023e-33, 1.0, 3.3245113e-26, 0.0, 0.0, 7.889453e-34, 0.0, 1.337579e-26, 0.0]\n"
     ]
    }
   ],
   "source": [
    "main = Tk()\n",
    "main.title(\"MNIST Digits, Neural Network\")\n",
    "main.geometry()\n",
    "\n",
    "t_aVal  = IntVar(value=1)\n",
    "t_aSpbox = Spinbox(main, textvariable=t_aVal ,from_=0, to=10000, increment=1)\n",
    "t_aSpbox.grid(row=0,column=1)\n",
    "t_aLabel=Label(main, text='Numer of Digits : ')                \n",
    "t_aLabel.grid(row=0,column=0)\n",
    "# 스핀 박스에 선택한 숫자를 인덱스로 해서 10000 개의 test 데이터중 입력된 인덱스 \n",
    "# 번째의 이미지를 불러오기 위한 버튼 - viewImage() 함수에 연결\n",
    "btn1 = Button(main,text=\"viewImage\", height=1,command=lambda:viewImage())\n",
    "btn1.grid(row=0, column=2, sticky=(W, E))\n",
    "\n",
    "# train 횟수를 지정하는 스핀박스와 라벨\n",
    "t_tVal  = IntVar(value=100)\n",
    "t_tSpbox = Spinbox(main, textvariable=t_tVal ,from_=0, to=100000, increment=100, )\n",
    "t_tSpbox.config(state='readonly')\n",
    "t_tSpbox.grid(row=0,column=4)\n",
    "t_tLabel=Label(main, text='Number of trains : ')                \n",
    "t_tLabel.grid(row=0,column=3)\n",
    "\n",
    "digit_canvas = FigureCanvasTkAgg(digit_fig, main)\n",
    "digit_canvas.get_tk_widget().grid(row=1,column=0,columnspan=3) \n",
    "\n",
    "btn2 = Button(main,text=\"Deep Learing\", height=1,command=lambda:learning())\n",
    "btn2.grid(row=0, column=5, sticky=(W, E))\n",
    "\n",
    "loss_canvas = FigureCanvasTkAgg(loss_fig, main)\n",
    "loss_canvas.get_tk_widget().grid(row=1,column=3,columnspan=3) \n",
    "\n",
    "acc_canvas = FigureCanvasTkAgg(acc_fig, main)\n",
    "acc_canvas.get_tk_widget().grid(row=2,column=0,columnspan=3)\n",
    "\n",
    "number_canvas = FigureCanvasTkAgg(number_fig, main)\n",
    "number_canvas.get_tk_widget().grid(row=2,column=3,columnspan=3)\n",
    "\n",
    "main.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
