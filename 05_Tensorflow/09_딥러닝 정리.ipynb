{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning 정리\n",
    "1. 인간의 뇌에 각각 가장 작은 단위로 존재하는 뉴럴을 모방하여 만든 인공지능 구조입니다\n",
    "1. 간단한 개념의 인공 뉴런을 충분히 많이 연결하여 놓아, 인간이 인지 하기 어려운 매우 복잡한 패턴을 스스로 학습하게 합니다\n",
    "1. 수천, 수만개의 W값과 b 값의 조합을 변경해 가면서 계산합니다\n",
    "1. 하지만 이는 매우 오랜 시간이 걸려서 신경망 훈련은 초반에 많은 어려움이 있었습니다\n",
    "1. 신경만의 층이 깊어질수록 시도해봐야하는 조합이 기하급수로 늘어나서 과거에는 유의미한 신경망 제작은 거의 불가능했었습니다\n",
    "1. 이후 끊임없는 연구를 통해 신경망 학습 알고리즘이 개발되었고, 심층 신경망 학습을 증명하면서 다시 신경망이 화자되기 시작했습니다\n",
    "1. 드롭 아웃, ReLU 등의 액티배이션 함수 개방로 급속 발전, 또한 수치계산과 병렬 처리에 쓰이는 GPU 발전으로 더욱 딥러닝발전에 기여하였습니다\n",
    "1. 이 발전의 중심에 역전파(BackPropagation) 이 있습니다\n",
    "1. 출력층이 내놓은 결과의 오차를 입력층 까지 역으로 전파 해서 계산해 나가는 방식으로 기존방식보다 최적화 과정이 빠르고 정확해 집니다\n",
    "1. 역전파는 신경망 사용시 항상 적용해야 하는 알고리즘이지만 구현이 어려움 다만 텐서 플로 에서 역전파 기법을 기본으로 제공하므로 간단히 사용할 수 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 머신러닝과 딥러닝의 비교\n",
    "1. 머신러닝은 회귀식이나 코스트 함수식을 보고 입력값이 출력값에 영향을 주는 구조를 설명할 수 있습니다\n",
    "1. 신경망은 그런 설명이 불가능합니다\n",
    "1. 집값에 영향을 주는 요인에 주변 공원 갯수, 지하철역 유무 등으로 판단한다면 모델의 정확도는 70~80% 선에서 유지. 즉 모델의 현상을 설명하긴 좋으나 정확성은 상대적으로 낮음\n",
    "1. 딥러닝(신경망)은 주변공원 갯수 지하철역이 0~1.0 만큼의 내용을 나눠갖는니 어쩌느니가 설명이 안되는 구조입니다\n",
    "1. 수많은 변수의 값으로 출력하고 오차에 대한 재연산등을 셀 수 없이 반복하며 학습 하기에 변수의 요소가 어떻게 집값에 영향을 주는지 말로는 설명이 안됩니다\n",
    "1. 하지만 정확도가 95% 이상이기 때문에 주어진 요소로 예측된 값을 활용하기에 최적합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
